{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Search Engine\r\n",
    "The goal of this notebook is to start to explore ways of creating a simple search engine to explore books.  \r\n",
    "The general approach will be as follows.  \r\n",
    "  - Create word vectors of each of the sentences in the book.\r\n",
    "  - Use something like the package `annoy` to create an index of the sentence vectors in the book (we will use sklearn for now).\r\n",
    "  - Search terms will be assigned a vector and can be compared against the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "from sklearn.neighbors import NearestNeighbors\r\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for testing, we are using pretrained models from `spaCy`, this could be expanded by updating the model, using the text from the book we want to search. This would help refine out searches and get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the spaCy model object, this is what is interacted with for\r\n",
    "# text processing.\r\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the book into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\r\n",
    "    \"resources/the-hound-of-baskervilles.txt\", mode=\"r\", encoding=\"utf8\"\r\n",
    ") as file:\r\n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will trim down the book, dropping the title page, and table of contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter1_idx = book.index(\"CHAPTER I\")\r\n",
    "book_trim = book[chapter1_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER I\n",
      "    Mr. Sherlock Holmes\n",
      "\n",
      "\n",
      "Mr. Sherlock Holmes, who was usually very late in the mornings, save\n",
      "upon those not infrequent occasions when he was ...\n"
     ]
    }
   ],
   "source": [
    "print(book_trim[0:152], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here process the book using the spacy model we loaded in earlier. There are more efficient things we could do to speed this process up, but for now this is good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_doc = nlp(book_trim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned data structure from the spacy model can be queried to get useful data for our needs. For instances we can loop over all of the sentences in the book saving that into a list for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bks = [s for s in full_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "spacy.tokens.span.Span"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bks[0].__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the actual returned \"sentence\" is a smaller spacy document object we can cotinue to work with. Next we will use these spacy sentence objects to grab the word vectors from each sentence. This is the numerical representation of the sentences meaning, this is what we will be searching against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.02991001,  0.41294003,  0.05577499, -0.624195  ,  0.17363301,\n        0.0434285 ,  0.38105   , -0.07594499,  0.279755  ,  1.78855   ],\n      dtype=float32)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of some output from the sentence vector of the first sentence.\r\n",
    "bks[0].vector[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of sentence vectors and sentence text\n",
    "# svc = normalize(np.array([s.vector for s in bks]), axis=1, norm=\"l1\")\n",
    "svc = np.array([s.vector for s in bks])\n",
    "stx = np.array([s.text for s in bks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to now fit our sentence vectors with a nearest neighbors model, this will allow us to efficiently search the sentences with the sentence vector of our search phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "NearestNeighbors(leaf_size=3, n_neighbors=3)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnb = NearestNeighbors(leaf_size=3, n_neighbors=3)\r\n",
    "nnb.fit(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is an example of searching... We will use a phrase, get the word vector for that phrase, and then find the indices of the closest sentences. This is the results the user can see. Again, because we know the location of the sentence in the book, we can use that to return them to the book location to read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the dog?\" \n",
      "\n",
      "\"Has been in the habit of carrying this stick behind his master. \n",
      "Being a heavy stick the dog has held it tightly by the middle, and\n",
      "the marks of his teeth are very plainly visible.\n",
      "______________________________\n",
      "The giant hound was dead. \n",
      "\n",
      " Sir Henry lay insensible where he had fallen.\n",
      "______________________________\n",
      "A sheep-dog of the moor? Or a spectral hound, black, silent, and\n",
      "monstrous? Was there a human agency in the matter?\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "answer = nnb.kneighbors([nlp(\"the canine\").vector], return_distance=False)\r\n",
    "for i in answer.flatten():\r\n",
    "    t = [s for s in stx[i : (i + 3)]]\r\n",
    "    print(\" \".join(t), end=f\"\\n{'_'*30}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we search for \"the canine\" and return sentences with meaning that are similar to this. None of these sentences have the word canine in them, but because the meaning of \"the canine\" is close to dog, it is returning results with dogs, and hound in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note On Word Vectors\r\n",
    "Word vectors (also known as word embeddins, and sentence embeddings depending on the context) provide a way for us to represent words in vector space. One of the most common models for creating them is Word2Vec. The closer a word is to another word in vector space, the more similar the meanings are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cosine_similarity(w1, w2, model):\r\n",
    "    return 1 - cosine(model.vocab[w1].vector, model.vocab[w2].vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other text similarity measurements, such as edit distance, or soundex are looking to see if the word has similar spelling. Word vectors consider semantic similarity instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.06580065190792084"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cosine_similarity(\"farmer\", \"framer\", nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5305896997451782"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cosine_similarity(\"farmer\", \"agriculture\", nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the words \"farmer\" and \"farmer\" though spelled the same, are not very similar from a meaning perspective. However the words \"farmer\" and \"agriculture\" are much more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}